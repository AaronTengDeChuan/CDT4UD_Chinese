torch.cat()
torch.stack()

torch.unsqueeze()


nn.NLLLoss(size_average=True, ignore_index=0)

问题概述
	cdt2ud		使用UD的标注标准 标注CDT数据
	CDT标准
		词性 			29种
		依存句法关系		14种
	UD标准
		词性				17种
		通用依存句法		

########	
	列出两种标准的词性
	举例子说明 两种标准为什么不能简单的规则转换
	比如：统计出	
			多对多
			一对多
			多对一
		这些情况
########

	挑战


数据准备
	繁体转简体
		UD数据的繁体转简体
		github地址：https://github.com/skydark/nstools/tree/master/zhtools
	手动标注数据集

########
	说清楚数据的来源：		CDT中的句子
	说清楚标注采用的标准：	UD标准
########

		250句CDT数据，随机抽取
		动机
			通过观察数据发现，UD数据中许多词汇的词性不符合UD的理念，手动标注我们认为更符合UD标准的数据
########
	举例子说明UD中文数据中哪些词不符合UD的标准或者理念
	并列出我们想要如何更改，比如针对UD中文数据中这些不恰当的词性做更改
########

			作为测试集
			标注更多的CDT2UD数据，作为训练集

词性标注
	利用在UD数据上训练的词性标注模型预测
		模型
			双向LSTM网络
			初始化的词向量

########
	展示模型的结构，比如画图
########

		在UD的开发集上的结果：		87.83%
		在CDT的开发集上的结果：		95.30%

########
	目前模型的性能不够高
	性能低于 tensorflow，以及 udpipe 实现的词性标注器
	继续优化或者找模型的问题
########

		在cdt2ud测试集上的结果：	63.33%(64.22%)
		问题分析
			UD数据较少：3997句
			许多CDT数据中的词未在UD数据中出现
			cdt2ud测试集与UD数据集的词性标注标准存在一定的差异
		解决方法
			利用CDT数据集：55000句
			使用多任务学习方法使网络学到更多的CDT数据的句子结构信息

多任务学习

########
	展示多任务学习的模型结构（模型结构图片）
	说明模型的哪些部分是共享的， 哪些是与任务相关的
	说清楚训练时怎么利用模型，预测时怎么利用模型，即数据流的流动轨迹
########

	预训练（Pre Train）
		先训练UD，再训练CDT
			在cdt2ud测试集上的结果：62.57%(72.10%)
		先训练CDT，再训练UD
			在cdt2ud测试集上的结果：77.12%(84.03%)
		比较表格
	联合训练（Joint Train）
		同时训练UD和CDT
			loss = 1/(1+r) * UDLoss + r/(1+r) * CDTLoss
		r值的影响
			74.00%(80.08%)			r=0.1
			87.11%(87.71%)			r=1
			87.14%(87.73%)			r=10

########
	不能光列出结果，还是结合实验分析结果的原因
########

	比较表格
						acc
	UD 					63.33%(64.22%)
	Pre Train(UD+CDT)	62.57%(72.10%)
	Pre Train(CDT+UD)	77.12%(84.03%)
	Joint Train(r=0.1)	74.00%(80.08%)
	Joint Train(r=1)	87.11%(87.71%)	
	Joint Train(r=10)	87.14%(87.73%)
未来的工作
	标注更多的CDT2UD数据，作为训练集
	Parsing 的转换

